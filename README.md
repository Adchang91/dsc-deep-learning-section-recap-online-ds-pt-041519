
# Section Recap

## Introduction

This short lesson summarizes key takeaways from section 41.

## Objectives
You will be able to:
* Understand and explain what was covered in this section
* Understand and explain why this section will help you become a data scientist

## Key Takeaways

The key takeaways from this section include:

* Deep neural network presentations can lighten the burden and automate certain tasks of heavy data preprocessing
* Deep representations need exponentially fewer hidden units than shallow networks, to obtain the same performance
* Parameter initialization, forward propagation, cost function evualation and backward propagation are again the cornerstones of deep networks
* Tensors are the building blocks of neural networks and a good understanding of them and how to use them in Python is crucial
* scalars can be seen as 0D tensors. vectors can be seen as 1D tensors and Matrices are 2D tensors
* The usage of tensors reaches beyond matrices: tensors can have N dimensions
* Tensors can be created and manipulated using Numpy
* Keras makes building neural networks in Python easy, and you learned how to do that in this section
* You can use Keras to do some NLP as well, e.g. for tokenization
